{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c5a5d3",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25244d3a",
   "metadata": {},
   "source": [
    "## Setup & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3093d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_orig   : shape=(2466130, 9)\n",
      "dh_dnn    : shape=(920225, 8)\n",
      "surf_orig : shape=(981318, 6)\n",
      "surf_dnn  : shape=(544886, 5)\n"
     ]
    }
   ],
   "source": [
    "# Setup & load\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define project paths\n",
    "project_root      = Path.cwd().parent\n",
    "TASK1_CLEAN_DIR   = project_root / \"reports\" / \"task1\" / \"cleaned\"\n",
    "TASK2_DIR         = project_root / \"reports\" / \"task2\"\n",
    "TASK2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "csv_paths = {\n",
    "    \"dh_orig\":   TASK1_CLEAN_DIR / \"drillhole_original_clean.csv\",\n",
    "    \"dh_dnn\":    TASK1_CLEAN_DIR / \"drillhole_dnn_clean.csv\",\n",
    "    \"surf_orig\": TASK1_CLEAN_DIR / \"surface_original_clean.csv\",\n",
    "    \"surf_dnn\":  TASK1_CLEAN_DIR / \"surface_dnn_clean.csv\",\n",
    "}\n",
    "\n",
    "# Load CSVs\n",
    "dfs = {k: pd.read_csv(v) for k, v in csv_paths.items()}\n",
    "\n",
    "df_dh_orig_clean   = dfs[\"dh_orig\"]\n",
    "df_dh_dl_clean     = dfs[\"dh_dnn\"]\n",
    "df_surf_orig_clean = dfs[\"surf_orig\"]\n",
    "df_surf_dl_clean   = dfs[\"surf_dnn\"]\n",
    "\n",
    "# Print basic info\n",
    "for k, df in dfs.items():\n",
    "    print(f\"{k:10s}: shape={df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5d281",
   "metadata": {},
   "source": [
    "### Summarize Latitude/Longitude Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7fa07f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Count</th>\n",
       "      <th>LatMin</th>\n",
       "      <th>LatMax</th>\n",
       "      <th>LonMin</th>\n",
       "      <th>LonMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drillhole Original</td>\n",
       "      <td>2466130</td>\n",
       "      <td>-34.945354</td>\n",
       "      <td>-27.025372</td>\n",
       "      <td>114.675570</td>\n",
       "      <td>122.131294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drillhole DNN</td>\n",
       "      <td>920225</td>\n",
       "      <td>-34.945354</td>\n",
       "      <td>-27.025372</td>\n",
       "      <td>114.676380</td>\n",
       "      <td>122.107080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surface Original</td>\n",
       "      <td>981318</td>\n",
       "      <td>-34.990154</td>\n",
       "      <td>-26.915041</td>\n",
       "      <td>114.519930</td>\n",
       "      <td>122.135070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surface DNN</td>\n",
       "      <td>544886</td>\n",
       "      <td>-34.927277</td>\n",
       "      <td>-27.102000</td>\n",
       "      <td>114.547104</td>\n",
       "      <td>122.122314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset    Count     LatMin     LatMax      LonMin      LonMax\n",
       "0  Drillhole Original  2466130 -34.945354 -27.025372  114.675570  122.131294\n",
       "1       Drillhole DNN   920225 -34.945354 -27.025372  114.676380  122.107080\n",
       "2    Surface Original   981318 -34.990154 -26.915041  114.519930  122.135070\n",
       "3         Surface DNN   544886 -34.927277 -27.102000  114.547104  122.122314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Latitude/Longitude coverage summary\n",
    "\n",
    "def extent_for(df: pd.DataFrame, lat_col: str, lon_col: str) -> dict:\n",
    "    lat = pd.to_numeric(df[lat_col], errors=\"coerce\").dropna()\n",
    "    lon = pd.to_numeric(df[lon_col], errors=\"coerce\").dropna()\n",
    "    return {\n",
    "        \"LatMin\": lat.min() if not lat.empty else None,\n",
    "        \"LatMax\": lat.max() if not lat.empty else None,\n",
    "        \"LonMin\": lon.min() if not lon.empty else None,\n",
    "        \"LonMax\": lon.max() if not lon.empty else None,\n",
    "        \"Count\": int(df.shape[0])\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "datasets = {\n",
    "    \"Drillhole Original\": (df_dh_orig_clean, \"LATITUDE\", \"LONGITUDE\"),\n",
    "    \"Drillhole DNN\":      (df_dh_dl_clean,   \"LATITUDE\", \"LONGITUDE\"),\n",
    "    \"Surface Original\":   (df_surf_orig_clean, \"DLAT\", \"DLONG\"),\n",
    "    \"Surface DNN\":        (df_surf_dl_clean,   \"DLAT\", \"DLONG\"),\n",
    "}\n",
    "\n",
    "for name, (df, lat_col, lon_col) in datasets.items():\n",
    "    if {lat_col, lon_col}.issubset(df.columns):\n",
    "        e = extent_for(df, lat_col, lon_col)\n",
    "        e[\"Dataset\"] = name\n",
    "        rows.append(e)\n",
    "\n",
    "extents_df = pd.DataFrame(rows)[[\"Dataset\",\"Count\",\"LatMin\",\"LatMax\",\"LonMin\",\"LonMax\"]]\n",
    "display(extents_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd088e3",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "A subset for testing (here I set up the same region as in the paper).\n",
    "Can either use this smaller dataset to focus only on the study area, or use the full cleaned datasets for broader analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdc9b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Drillhole Original -> rows=403\n",
      "[SAVE] Drillhole DNN      -> rows=294\n",
      "[SAVE] Surface Original   -> rows=210\n",
      "[SAVE] Surface DNN        -> rows=531\n",
      "Saved Task2 sample datasets to: ../reports/task2/sample_csv\n"
     ]
    }
   ],
   "source": [
    "# Define a bounding box (latitude/longitude region)\n",
    "lat_min, lat_max = -30.0, -27.5\n",
    "lon_min, lon_max = 120.0, 121.5\n",
    "\n",
    "def filter_by_bbox(df: pd.DataFrame, lat_col: str, lon_col: str) -> pd.DataFrame:\n",
    "    lat = pd.to_numeric(df[lat_col], errors=\"coerce\")\n",
    "    lon = pd.to_numeric(df[lon_col], errors=\"coerce\")\n",
    "    mask = (\n",
    "        lat.notna() & lon.notna() &\n",
    "        (lat >= lat_min) & (lat <= lat_max) &\n",
    "        (lon >= lon_min) & (lon <= lon_max)\n",
    "    )\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "# Use relative path (like in Task1)\n",
    "SAMPLE_DIR = Path(\"../reports/task2/sample_csv\")\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Filter and export\n",
    "samples = {}\n",
    "for name, (df, lat_col, lon_col) in datasets.items():\n",
    "    if {lat_col, lon_col}.issubset(df.columns):\n",
    "        sub = filter_by_bbox(df, lat_col, lon_col)\n",
    "        samples[name] = sub\n",
    "        out_path = SAMPLE_DIR / f\"{name.lower().replace(' ', '_')}_sample.csv\"\n",
    "        sub.to_csv(out_path, index=False)\n",
    "        print(f\"[SAVE] {name:18s} -> rows={sub.shape[0]}\")\n",
    "\n",
    "print(\"Saved Task2 sample datasets to:\", SAMPLE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2258f",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb84172",
   "metadata": {},
   "source": [
    "## Drillhole Comparison: ORIG vs DL\n",
    "\n",
    "This notebook processes two drillhole datasets:\n",
    "- **ORIG**: original assay values  \n",
    "- **DL**: values predicted by the deep learning model  \n",
    "\n",
    "We align them on both:\n",
    "1. Longitude/latitude grid cells  \n",
    "2. Overlapping depth intervals  \n",
    "\n",
    "**Diff logic**\n",
    "diff = DL - ORIG (default)  \n",
    "\n",
    "**Outputs**\n",
    "1. `*_overlaps.csv`: detailed overlapping intervals  \n",
    "2. `*_points.csv`: representative points (depth midpoints), used for 3D visualization in Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34e2a0",
   "metadata": {},
   "source": [
    "### Envrionment & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d832bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: cleaned DataFrames \n",
    "# - df_dh_orig_clean\n",
    "# - df_dh_dl_clean\n",
    "\n",
    "# Output directory (relative to project root)\n",
    "OUT_DIR = Path(\"../reports/task2\")\n",
    "BASE_NAME = \"drillhole\"\n",
    "\n",
    "# Key parameters\n",
    "GRID_STEP_DEG = 1e-4   # grid size in degrees (~10 m)\n",
    "Z_STEP_M      = 1.0    # depth bin size in meters\n",
    "DIFF_MODE     = \"dl_minus_orig\"  # or \"orig_minus_dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "830c5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions \n",
    "def to_numeric(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def snap_xy_to_grid(df: pd.DataFrame,\n",
    "                    lon_col=\"LONGITUDE\",\n",
    "                    lat_col=\"LATITUDE\",\n",
    "                    step=1e-4) -> pd.DataFrame:\n",
    "    \"\"\"Snap longitude/latitude to regular grid.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"_gx\"] = np.floor(df[lon_col] / step).astype(np.int64)\n",
    "    df[\"_gy\"] = np.floor(df[lat_col] / step).astype(np.int64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae100c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align by XY & Depth Interval\n",
    "def align_by_xy_and_depth_interval(\n",
    "    df_orig, df_dl,\n",
    "    lon_col=\"LONGITUDE\", lat_col=\"LATITUDE\",\n",
    "    from_col=\"FROMDEPTH\", to_col=\"TODEPTH\",\n",
    "    cu_col=\"Cu_ppm\",\n",
    "    grid_step=1e-4,\n",
    "    diff_mode=\"dl_minus_orig\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Align ORIG and DL by (lon,lat) grid and overlapping depth intervals.\n",
    "    Returns overlaps with both Cu values and diff.\n",
    "    \"\"\"\n",
    "    need = [lon_col, lat_col, from_col, to_col, cu_col]\n",
    "    A = to_numeric(df_orig[need].dropna(), need)\n",
    "    B = to_numeric(df_dl  [need].dropna(), need)\n",
    "\n",
    "    A = A.loc[A[from_col] < A[to_col]].copy()\n",
    "    B = B.loc[B[from_col] < B[to_col]].copy()\n",
    "\n",
    "    A = snap_xy_to_grid(A, lon_col, lat_col, step=grid_step)\n",
    "    B = snap_xy_to_grid(B, lon_col, lat_col, step=grid_step)\n",
    "\n",
    "    parts = []\n",
    "    for (gx, gy), gA in A.groupby([\"_gx\", \"_gy\"]):\n",
    "        gB = B[(B[\"_gx\"] == gx) & (B[\"_gy\"] == gy)]\n",
    "        if gB.empty: continue\n",
    "\n",
    "        gA = gA.rename(columns={from_col:\"fromA\", to_col:\"toA\", cu_col:\"Cu_orig\",\n",
    "                                lon_col:\"lonA\", lat_col:\"latA\"})\n",
    "        gB = gB.rename(columns={from_col:\"fromB\", to_col:\"toB\", cu_col:\"Cu_dl\",\n",
    "                                lon_col:\"lonB\", lat_col:\"latB\"})\n",
    "        gA[\"__k\"] = 1; gB[\"__k\"] = 1\n",
    "        M = gA.merge(gB, on=\"__k\").drop(columns=\"__k\")\n",
    "\n",
    "        M = M.loc[(M[\"fromA\"] < M[\"toB\"]) & (M[\"fromB\"] < M[\"toA\"])].copy()\n",
    "        if M.empty: continue\n",
    "\n",
    "        M[\"from\"] = M[[\"fromA\",\"fromB\"]].max(axis=1)\n",
    "        M[\"to\"]   = M[[\"toA\",\"toB\"]].min(axis=1)\n",
    "        M = M.loc[M[\"from\"] < M[\"to\"]].copy()\n",
    "        if M.empty: continue\n",
    "\n",
    "        if diff_mode == \"dl_minus_orig\":\n",
    "            M[\"diff\"] = M[\"Cu_dl\"] - M[\"Cu_orig\"]\n",
    "        else:\n",
    "            M[\"diff\"] = M[\"Cu_orig\"] - M[\"Cu_dl\"]\n",
    "\n",
    "        M[\"_gx\"] = gx; M[\"_gy\"] = gy\n",
    "        parts.append(M[[\"from\",\"to\",\"Cu_orig\",\"Cu_dl\",\"diff\",\n",
    "                        \"lonA\",\"latA\",\"lonB\",\"latB\",\"_gx\",\"_gy\"]])\n",
    "\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "53e330fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Overlaps to Points\n",
    "def overlaps_to_points(aligned, grid_step=1e-4, z_step=1.0, agg=\"mean\"):\n",
    "    \"\"\"\n",
    "    Convert overlap intervals into representative 3D points.\n",
    "    DEPTH = midpoint; LONG/LAT = average of both sides.\n",
    "    \"\"\"\n",
    "    if aligned is None or len(aligned) == 0:\n",
    "        return pd.DataFrame(columns=[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\"])\n",
    "\n",
    "    df = aligned.copy()\n",
    "    df[\"DEPTH\"] = (df[\"from\"] + df[\"to\"]) / 2.0\n",
    "    df[\"LONGITUDE\"] = (df[\"lonA\"] + df[\"lonB\"]) / 2.0\n",
    "    df[\"LATITUDE\"]  = (df[\"latA\"] + df[\"latB\"]) / 2.0\n",
    "    df = df.rename(columns={\"Cu_orig\":\"CU_ORIG\",\"Cu_dl\":\"CU_DL\",\"diff\":\"DIFF\"})\n",
    "\n",
    "    df[\"_gx\"] = np.floor(df[\"LONGITUDE\"]/grid_step).astype(np.int64)\n",
    "    df[\"_gy\"] = np.floor(df[\"LATITUDE\"]/grid_step).astype(np.int64)\n",
    "    df[\"_gz\"] = np.floor(df[\"DEPTH\"]/z_step).astype(np.int64)\n",
    "\n",
    "    grouped = (\n",
    "        df.groupby([\"_gx\",\"_gy\",\"_gz\"], as_index=False)\n",
    "          .agg({\"LONGITUDE\":agg,\"LATITUDE\":agg,\"DEPTH\":agg,\n",
    "                \"CU_ORIG\":agg,\"CU_DL\":agg,\"DIFF\":agg})\n",
    "    )\n",
    "    return grouped[[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e8eae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Function\n",
    "def process_drillhole_pair_csv(\n",
    "    df_orig, df_dl,\n",
    "    out_dir=\"reports/task2\",\n",
    "    base_name=\"drillhole\",\n",
    "    grid_step=1e-4,\n",
    "    z_step=1.0,\n",
    "    diff_mode=\"dl_minus_orig\"\n",
    "):\n",
    "    \"\"\"Run pipeline and save CSVs.\"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    aligned = align_by_xy_and_depth_interval(\n",
    "        df_orig, df_dl, grid_step=grid_step, diff_mode=diff_mode\n",
    "    )\n",
    "    print(f\"[INFO] overlaps: {len(aligned)}\")\n",
    "\n",
    "    points = overlaps_to_points(aligned, grid_step=grid_step, z_step=z_step, agg=\"mean\")\n",
    "    print(f\"[INFO] points: {len(points)}\")\n",
    "\n",
    "    overlaps_csv = Path(out_dir) / f\"{base_name}_overlaps.csv\"\n",
    "    points_csv   = Path(out_dir) / f\"{base_name}_points.csv\"\n",
    "    aligned.to_csv(overlaps_csv, index=False)\n",
    "    points.to_csv(points_csv, index=False)\n",
    "\n",
    "    print(f\"[SAVE] {overlaps_csv}\")\n",
    "    print(f\"[SAVE] {points_csv}\")\n",
    "    return str(overlaps_csv), str(points_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30956140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] overlaps: 260797\n",
      "[INFO] points: 90439\n",
      "[SAVE] ../reports/task2/drillhole_overlaps.csv\n",
      "[SAVE] ../reports/task2/drillhole_points.csv\n"
     ]
    }
   ],
   "source": [
    "overlap_path, points_path = process_drillhole_pair_csv(\n",
    "    df_dh_orig_clean, df_dh_dl_clean,\n",
    "    out_dir=OUT_DIR,\n",
    "    base_name=BASE_NAME,\n",
    "    grid_step=GRID_STEP_DEG,\n",
    "    z_step=Z_STEP_M,\n",
    "    diff_mode=DIFF_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d28e11",
   "metadata": {},
   "source": [
    "**Method**\n",
    "\n",
    "**Drillhole Diff Method**\n",
    "1. Grid snapping (XY):\n",
    "\n",
    "Longitude & latitude are snapped to grid cells of size grid_step.\n",
    "\n",
    "2.Depth intervals (Z):\n",
    "Each record is an interval [FROM, TO] rather than a single depth.\n",
    "\n",
    "3. Overlap rule:\n",
    "Two intervals are compared only if they overlap in the same XY cell.\n",
    "\n",
    "Intersection only:\n",
    "If [fromA,toA] and [fromB,toB] overlap, keep the intersecting part.\n",
    "- Diff calculation:\n",
    "\tdiff = Cu_dl – Cu_orig (or the reverse, depending on mode).\n",
    "\n",
    "Outputs:\n",
    "- Overlap intervals with both Cu values and diff\n",
    "- Point cloud representation (midpoints of overlaps) for 3D mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3645816",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
