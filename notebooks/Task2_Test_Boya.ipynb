{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c5a5d3",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25244d3a",
   "metadata": {},
   "source": [
    "## Setup & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3093d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_orig   : shape=(2466130, 9)\n",
      "dh_dnn    : shape=(920225, 8)\n",
      "surf_orig : shape=(981318, 6)\n",
      "surf_dnn  : shape=(544886, 5)\n"
     ]
    }
   ],
   "source": [
    "# Setup & load\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define project paths\n",
    "project_root      = Path.cwd().parent\n",
    "TASK1_CLEAN_DIR   = project_root / \"reports\" / \"task1\" / \"cleaned\"\n",
    "TASK2_DIR         = project_root / \"reports\" / \"task2\"\n",
    "TASK2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "csv_paths = {\n",
    "    \"dh_orig\":   TASK1_CLEAN_DIR / \"drillhole_original_clean.csv\",\n",
    "    \"dh_dnn\":    TASK1_CLEAN_DIR / \"drillhole_dnn_clean.csv\",\n",
    "    \"surf_orig\": TASK1_CLEAN_DIR / \"surface_original_clean.csv\",\n",
    "    \"surf_dnn\":  TASK1_CLEAN_DIR / \"surface_dnn_clean.csv\",\n",
    "}\n",
    "\n",
    "# Load CSVs\n",
    "dfs = {k: pd.read_csv(v) for k, v in csv_paths.items()}\n",
    "\n",
    "df_dh_orig_clean   = dfs[\"dh_orig\"]\n",
    "df_dh_dl_clean     = dfs[\"dh_dnn\"]\n",
    "df_surf_orig_clean = dfs[\"surf_orig\"]\n",
    "df_surf_dl_clean   = dfs[\"surf_dnn\"]\n",
    "\n",
    "# Print basic info\n",
    "for k, df in dfs.items():\n",
    "    print(f\"{k:10s}: shape={df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5d281",
   "metadata": {},
   "source": [
    "### Summarize Latitude/Longitude Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa07f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Count</th>\n",
       "      <th>LatMin</th>\n",
       "      <th>LatMax</th>\n",
       "      <th>LonMin</th>\n",
       "      <th>LonMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drillhole Original</td>\n",
       "      <td>2466130</td>\n",
       "      <td>-34.945354</td>\n",
       "      <td>-27.025372</td>\n",
       "      <td>114.675570</td>\n",
       "      <td>122.131294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drillhole DNN</td>\n",
       "      <td>920225</td>\n",
       "      <td>-34.945354</td>\n",
       "      <td>-27.025372</td>\n",
       "      <td>114.676380</td>\n",
       "      <td>122.107080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surface Original</td>\n",
       "      <td>981318</td>\n",
       "      <td>-34.990154</td>\n",
       "      <td>-26.915041</td>\n",
       "      <td>114.519930</td>\n",
       "      <td>122.135070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surface DNN</td>\n",
       "      <td>544886</td>\n",
       "      <td>-34.927277</td>\n",
       "      <td>-27.102000</td>\n",
       "      <td>114.547104</td>\n",
       "      <td>122.122314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset    Count     LatMin     LatMax      LonMin      LonMax\n",
       "0  Drillhole Original  2466130 -34.945354 -27.025372  114.675570  122.131294\n",
       "1       Drillhole DNN   920225 -34.945354 -27.025372  114.676380  122.107080\n",
       "2    Surface Original   981318 -34.990154 -26.915041  114.519930  122.135070\n",
       "3         Surface DNN   544886 -34.927277 -27.102000  114.547104  122.122314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Latitude/Longitude coverage summary\n",
    "\n",
    "def extent_for(df: pd.DataFrame, lat_col: str, lon_col: str) -> dict:\n",
    "    lat = pd.to_numeric(df[lat_col], errors=\"coerce\").dropna()\n",
    "    lon = pd.to_numeric(df[lon_col], errors=\"coerce\").dropna()\n",
    "    return {\n",
    "        \"LatMin\": lat.min() if not lat.empty else None,\n",
    "        \"LatMax\": lat.max() if not lat.empty else None,\n",
    "        \"LonMin\": lon.min() if not lon.empty else None,\n",
    "        \"LonMax\": lon.max() if not lon.empty else None,\n",
    "        \"Count\": int(df.shape[0])\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "datasets = {\n",
    "    \"Drillhole Original\": (df_dh_orig_clean, \"LATITUDE\", \"LONGITUDE\"),\n",
    "    \"Drillhole DNN\":      (df_dh_dl_clean,   \"LATITUDE\", \"LONGITUDE\"),\n",
    "    \"Surface Original\":   (df_surf_orig_clean, \"DLAT\", \"DLONG\"),\n",
    "    \"Surface DNN\":        (df_surf_dl_clean,   \"DLAT\", \"DLONG\"),\n",
    "}\n",
    "\n",
    "for name, (df, lat_col, lon_col) in datasets.items():\n",
    "    if {lat_col, lon_col}.issubset(df.columns):\n",
    "        e = extent_for(df, lat_col, lon_col)\n",
    "        e[\"Dataset\"] = name\n",
    "        rows.append(e)\n",
    "\n",
    "extents_df = pd.DataFrame(rows)[[\"Dataset\",\"Count\",\"LatMin\",\"LatMax\",\"LonMin\",\"LonMax\"]]\n",
    "display(extents_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd088e3",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "A subset for testing (here I set up the same region as in the paper).\n",
    "Can either use this smaller dataset to focus only on the study area, or use the full cleaned datasets for broader analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc9b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Drillhole Original -> rows=403\n",
      "[SAVE] Drillhole DNN      -> rows=294\n",
      "[SAVE] Surface Original   -> rows=210\n",
      "[SAVE] Surface DNN        -> rows=531\n",
      "Saved Task2 sample datasets to: ../reports/task2/sample_csv\n"
     ]
    }
   ],
   "source": [
    "# Define a bounding box (latitude/longitude region)\n",
    "lat_min, lat_max = -30.0, -27.5\n",
    "lon_min, lon_max = 120.0, 121.5\n",
    "\n",
    "def filter_by_bbox(df: pd.DataFrame, lat_col: str, lon_col: str) -> pd.DataFrame:\n",
    "    lat = pd.to_numeric(df[lat_col], errors=\"coerce\")\n",
    "    lon = pd.to_numeric(df[lon_col], errors=\"coerce\")\n",
    "    mask = (\n",
    "        lat.notna() & lon.notna() &\n",
    "        (lat >= lat_min) & (lat <= lat_max) &\n",
    "        (lon >= lon_min) & (lon <= lon_max)\n",
    "    )\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "# Use relative path (like in Task1)\n",
    "SAMPLE_DIR = Path(\"../reports/task2/sample_csv\")\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Filter and export\n",
    "samples = {}\n",
    "for name, (df, lat_col, lon_col) in datasets.items():\n",
    "    if {lat_col, lon_col}.issubset(df.columns):\n",
    "        sub = filter_by_bbox(df, lat_col, lon_col)\n",
    "        samples[name] = sub\n",
    "        out_path = SAMPLE_DIR / f\"{name.lower().replace(' ', '_')}_sample.csv\"\n",
    "        sub.to_csv(out_path, index=False)\n",
    "        print(f\"[SAVE] {name:18s} -> rows={sub.shape[0]}\")\n",
    "\n",
    "print(\"Saved Task2 sample datasets to:\", SAMPLE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2258f",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb84172",
   "metadata": {},
   "source": [
    "## Drillhole Comparison: ORIG vs DL\n",
    "\n",
    "This notebook processes two drillhole datasets:\n",
    "- **ORIG**: original assay values  \n",
    "- **DL**: values predicted by the deep learning model  \n",
    "\n",
    "We align them on both:\n",
    "1. Longitude/latitude grid cells  \n",
    "2. Overlapping depth intervals  \n",
    "\n",
    "**Diff logic**\n",
    "diff = DL - ORIG (default)  \n",
    "\n",
    "**Outputs**\n",
    "1. `*_overlaps.csv`: detailed overlapping intervals  \n",
    "2. `*_points.csv`: representative points (depth midpoints), used for 3D visualization in Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34e2a0",
   "metadata": {},
   "source": [
    "### Envrionment & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d832bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: cleaned DataFrames \n",
    "# - df_dh_orig_clean\n",
    "# - df_dh_dl_clean\n",
    "\n",
    "# Output directory (relative to project root)\n",
    "OUT_DIR = Path(\"../reports/task2\")\n",
    "BASE_NAME = \"drillhole\"\n",
    "\n",
    "# Key parameters\n",
    "GRID_STEP_DEG = 1e-4   # grid size in degrees (~10 m)\n",
    "Z_STEP_M      = 1.0    # depth bin size in meters\n",
    "DIFF_MODE     = \"dl_minus_orig\"  # or \"orig_minus_dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830c5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions \n",
    "def to_numeric(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def snap_xy_to_grid(df: pd.DataFrame,\n",
    "                    lon_col=\"LONGITUDE\",\n",
    "                    lat_col=\"LATITUDE\",\n",
    "                    step=1e-4) -> pd.DataFrame:\n",
    "    \"\"\"Snap longitude/latitude to regular grid.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"_gx\"] = np.floor(df[lon_col] / step).astype(np.int64)\n",
    "    df[\"_gy\"] = np.floor(df[lat_col] / step).astype(np.int64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae100c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align by XY & Depth Interval\n",
    "def align_by_xy_and_depth_interval(\n",
    "    df_orig, df_dl,\n",
    "    lon_col=\"LONGITUDE\", lat_col=\"LATITUDE\",\n",
    "    from_col=\"FROMDEPTH\", to_col=\"TODEPTH\",\n",
    "    cu_col=\"Cu_ppm\",\n",
    "    grid_step=1e-4,\n",
    "    diff_mode=\"dl_minus_orig\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Align ORIG and DL by (lon,lat) grid and overlapping depth intervals.\n",
    "    Returns overlaps with both Cu values and diff.\n",
    "    \"\"\"\n",
    "    need = [lon_col, lat_col, from_col, to_col, cu_col]\n",
    "    A = to_numeric(df_orig[need].dropna(), need)\n",
    "    B = to_numeric(df_dl  [need].dropna(), need)\n",
    "\n",
    "    A = A.loc[A[from_col] < A[to_col]].copy()\n",
    "    B = B.loc[B[from_col] < B[to_col]].copy()\n",
    "\n",
    "    A = snap_xy_to_grid(A, lon_col, lat_col, step=grid_step)\n",
    "    B = snap_xy_to_grid(B, lon_col, lat_col, step=grid_step)\n",
    "\n",
    "    parts = []\n",
    "    for (gx, gy), gA in A.groupby([\"_gx\", \"_gy\"]):\n",
    "        gB = B[(B[\"_gx\"] == gx) & (B[\"_gy\"] == gy)]\n",
    "        if gB.empty: continue\n",
    "\n",
    "        gA = gA.rename(columns={from_col:\"fromA\", to_col:\"toA\", cu_col:\"Cu_orig\",\n",
    "                                lon_col:\"lonA\", lat_col:\"latA\"})\n",
    "        gB = gB.rename(columns={from_col:\"fromB\", to_col:\"toB\", cu_col:\"Cu_dl\",\n",
    "                                lon_col:\"lonB\", lat_col:\"latB\"})\n",
    "        gA[\"__k\"] = 1; gB[\"__k\"] = 1\n",
    "        M = gA.merge(gB, on=\"__k\").drop(columns=\"__k\")\n",
    "\n",
    "        M = M.loc[(M[\"fromA\"] < M[\"toB\"]) & (M[\"fromB\"] < M[\"toA\"])].copy()\n",
    "        if M.empty: continue\n",
    "\n",
    "        M[\"from\"] = M[[\"fromA\",\"fromB\"]].max(axis=1)\n",
    "        M[\"to\"]   = M[[\"toA\",\"toB\"]].min(axis=1)\n",
    "        M = M.loc[M[\"from\"] < M[\"to\"]].copy()\n",
    "        if M.empty: continue\n",
    "\n",
    "        if diff_mode == \"dl_minus_orig\":\n",
    "            M[\"diff\"] = M[\"Cu_dl\"] - M[\"Cu_orig\"]\n",
    "        else:\n",
    "            M[\"diff\"] = M[\"Cu_orig\"] - M[\"Cu_dl\"]\n",
    "\n",
    "        M[\"_gx\"] = gx; M[\"_gy\"] = gy\n",
    "        parts.append(M[[\"from\",\"to\",\"Cu_orig\",\"Cu_dl\",\"diff\",\n",
    "                        \"lonA\",\"latA\",\"lonB\",\"latB\",\"_gx\",\"_gy\"]])\n",
    "\n",
    "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e330fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Overlaps to Points\n",
    "def overlaps_to_points(aligned, grid_step=1e-4, z_step=1.0, agg=\"mean\"):\n",
    "    \"\"\"\n",
    "    Convert overlap intervals into representative 3D points.\n",
    "    DEPTH = midpoint; LONG/LAT = average of both sides.\n",
    "    \"\"\"\n",
    "    if aligned is None or len(aligned) == 0:\n",
    "        return pd.DataFrame(columns=[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\"])\n",
    "\n",
    "    df = aligned.copy()\n",
    "    df[\"DEPTH\"] = (df[\"from\"] + df[\"to\"]) / 2.0\n",
    "    df[\"LONGITUDE\"] = (df[\"lonA\"] + df[\"lonB\"]) / 2.0\n",
    "    df[\"LATITUDE\"]  = (df[\"latA\"] + df[\"latB\"]) / 2.0\n",
    "    df = df.rename(columns={\"Cu_orig\":\"CU_ORIG\",\"Cu_dl\":\"CU_DL\",\"diff\":\"DIFF\", \"diff_pct\":\"DIFF_PCT\"})\n",
    "\n",
    "    df[\"_gx\"] = np.floor(df[\"LONGITUDE\"]/grid_step).astype(np.int64)\n",
    "    df[\"_gy\"] = np.floor(df[\"LATITUDE\"]/grid_step).astype(np.int64)\n",
    "    df[\"_gz\"] = np.floor(df[\"DEPTH\"]/z_step).astype(np.int64)\n",
    "\n",
    "    grouped = (\n",
    "        df.groupby([\"_gx\",\"_gy\",\"_gz\"], as_index=False)\n",
    "          .agg({\"LONGITUDE\":agg,\"LATITUDE\":agg,\"DEPTH\":agg,\n",
    "                \"CU_ORIG\":agg,\"CU_DL\":agg,\"DIFF\":agg, \"DIFF_PCT\":  agg})\n",
    "    )\n",
    "    return grouped[[ \"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8eae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Function\n",
    "def process_drillhole_pair_csv(\n",
    "    df_orig, df_dl,\n",
    "    out_dir=\"reports/task2\",\n",
    "    base_name=\"drillhole\",\n",
    "    grid_step=1e-4,\n",
    "    z_step=1.0,\n",
    "    diff_mode=\"dl_minus_orig\"\n",
    "):\n",
    "    \"\"\"Run pipeline and save CSVs.\"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    aligned = align_by_xy_and_depth_interval(\n",
    "        df_orig, df_dl, grid_step=grid_step, diff_mode=diff_mode\n",
    "    )\n",
    "    print(f\"[INFO] overlaps: {len(aligned)}\")\n",
    "\n",
    "    eps = 1e-9\n",
    "    denom = aligned[\"Cu_dl\"].where(aligned[\"Cu_dl\"].abs() >= eps, np.nan)\n",
    "    aligned[\"diff_pct\"] = 100.0 * aligned[\"diff\"] / denom\n",
    "\n",
    "    points = overlaps_to_points(aligned, grid_step=grid_step, z_step=z_step, agg=\"mean\")\n",
    "    print(f\"[INFO] points: {len(points)}\")\n",
    "\n",
    "    overlaps_csv = Path(out_dir) / f\"{base_name}_overlaps.csv\"\n",
    "    points_csv   = Path(out_dir) / f\"{base_name}_points.csv\"\n",
    "    aligned.to_csv(overlaps_csv, index=False)\n",
    "    points.to_csv(points_csv, index=False)\n",
    "\n",
    "    print(f\"[SAVE] {overlaps_csv}\")\n",
    "    print(f\"[SAVE] {points_csv}\")\n",
    "    return str(overlaps_csv), str(points_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30956140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] overlaps: 260797\n",
      "[INFO] points: 90439\n",
      "[SAVE] ../reports/task2/drillhole_overlaps.csv\n",
      "[SAVE] ../reports/task2/drillhole_points.csv\n"
     ]
    }
   ],
   "source": [
    "overlap_path, points_path = process_drillhole_pair_csv(\n",
    "    df_dh_orig_clean, df_dh_dl_clean,\n",
    "    out_dir=OUT_DIR,\n",
    "    base_name=BASE_NAME,\n",
    "    grid_step=GRID_STEP_DEG,\n",
    "    z_step=Z_STEP_M,\n",
    "    diff_mode=DIFF_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d28e11",
   "metadata": {},
   "source": [
    "**Method**\n",
    "\n",
    "**Drillhole Diff Method**\n",
    "1. Grid snapping (XY):\n",
    "\n",
    "Longitude & latitude are snapped to grid cells of size grid_step.\n",
    "\n",
    "2.Depth intervals (Z):\n",
    "Each record is an interval [FROM, TO] rather than a single depth.\n",
    "\n",
    "3. Overlap rule:\n",
    "Two intervals are compared only if they overlap in the same XY cell.\n",
    "\n",
    "Intersection only:\n",
    "If [fromA,toA] and [fromB,toB] overlap, keep the intersecting part.\n",
    "- Diff calculation:\n",
    "\tdiff = Cu_dl – Cu_orig (or the reverse, depending on mode).\n",
    "\n",
    "Outputs:\n",
    "- Overlap intervals with both Cu values and diff\n",
    "- Point cloud representation (midpoints of overlaps) for 3D mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6256864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Cu_orig</th>\n",
       "      <th>Cu_dl</th>\n",
       "      <th>diff</th>\n",
       "      <th>lonA</th>\n",
       "      <th>latA</th>\n",
       "      <th>lonB</th>\n",
       "      <th>latB</th>\n",
       "      <th>_gx</th>\n",
       "      <th>_gy</th>\n",
       "      <th>diff_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.790</td>\n",
       "      <td>-70.210</td>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>1146766</td>\n",
       "      <td>-277687</td>\n",
       "      <td>-717.160368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.963</td>\n",
       "      <td>-36.037</td>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>1146766</td>\n",
       "      <td>-277687</td>\n",
       "      <td>-190.038496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.771</td>\n",
       "      <td>-47.229</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>1154136</td>\n",
       "      <td>-274190</td>\n",
       "      <td>-176.418513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.771</td>\n",
       "      <td>-47.229</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>1154136</td>\n",
       "      <td>-274190</td>\n",
       "      <td>-176.418513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.608</td>\n",
       "      <td>-73.392</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>1154136</td>\n",
       "      <td>-274190</td>\n",
       "      <td>-441.907514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from     to  Cu_orig   Cu_dl    diff       lonA       latA       lonB  \\\n",
       "0  133.0  134.0     80.0   9.790 -70.210  114.67665 -27.768700  114.67665   \n",
       "1  134.0  135.0     55.0  18.963 -36.037  114.67665 -27.768700  114.67665   \n",
       "2   45.0   46.0     74.0  26.771 -47.229  115.41368 -27.418915  115.41368   \n",
       "3   45.0   46.0     74.0  26.771 -47.229  115.41368 -27.418915  115.41368   \n",
       "4   39.0   40.0     90.0  16.608 -73.392  115.41368 -27.418915  115.41368   \n",
       "\n",
       "        latB      _gx     _gy    diff_pct  \n",
       "0 -27.768700  1146766 -277687 -717.160368  \n",
       "1 -27.768700  1146766 -277687 -190.038496  \n",
       "2 -27.418915  1154136 -274190 -176.418513  \n",
       "3 -27.418915  1154136 -274190 -176.418513  \n",
       "4 -27.418915  1154136 -274190 -441.907514  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>CU_ORIG</th>\n",
       "      <th>CU_DL</th>\n",
       "      <th>DIFF</th>\n",
       "      <th>DIFF_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>133.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.790</td>\n",
       "      <td>-70.210</td>\n",
       "      <td>-717.160368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.67665</td>\n",
       "      <td>-27.768700</td>\n",
       "      <td>134.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.963</td>\n",
       "      <td>-36.037</td>\n",
       "      <td>-190.038496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>31.5</td>\n",
       "      <td>243.0</td>\n",
       "      <td>59.017</td>\n",
       "      <td>-183.983</td>\n",
       "      <td>-311.745768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>39.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.608</td>\n",
       "      <td>-73.392</td>\n",
       "      <td>-441.907514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115.41368</td>\n",
       "      <td>-27.418915</td>\n",
       "      <td>45.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.771</td>\n",
       "      <td>-47.229</td>\n",
       "      <td>-176.418513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LONGITUDE   LATITUDE  DEPTH  CU_ORIG   CU_DL     DIFF    DIFF_PCT\n",
       "0  114.67665 -27.768700  133.5     80.0   9.790  -70.210 -717.160368\n",
       "1  114.67665 -27.768700  134.5     55.0  18.963  -36.037 -190.038496\n",
       "2  115.41368 -27.418915   31.5    243.0  59.017 -183.983 -311.745768\n",
       "3  115.41368 -27.418915   39.5     90.0  16.608  -73.392 -441.907514\n",
       "4  115.41368 -27.418915   45.5     74.0  26.771  -47.229 -176.418513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_overlaps = pd.read_csv(\"../reports/task2/drillhole_overlaps.csv\")\n",
    "df_points   = pd.read_csv(\"../reports/task2/drillhole_points.csv\")\n",
    "\n",
    "display(df_overlaps.head())\n",
    "display(df_points.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457c846",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f2fac",
   "metadata": {},
   "source": [
    "Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2458c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & global config ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Output directory: put everything under task2/difference\n",
    "OUT_DIR = Path(\"../reports/task2/difference\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Grid parameters\n",
    "GRID_STEP_DEG = 1e-4   # XY grid step in degrees (~10 m)\n",
    "Z_STEP_M      = 1.0    # Z bin size in meters\n",
    "\n",
    "# DIFF sign convention\n",
    "DIFF_MODE = \"dl_minus_orig\"   # or \"orig_minus_dl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2b1c3",
   "metadata": {},
   "source": [
    "Standardize helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b794d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standardize column names for both data types ---\n",
    "\n",
    "def standardize_drillhole(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure drillhole dataframe has consistent columns:\n",
    "    LON, LAT, FROM, TO, CU (+ keep anything else).\n",
    "    \"\"\"\n",
    "    rename_map = {\n",
    "        \"LONGITUDE\": \"LON\",\n",
    "        \"LATITUDE\":  \"LAT\",\n",
    "        \"FROMDEPTH\": \"FROM\",\n",
    "        \"TODEPTH\":   \"TO\",\n",
    "        \"Cu_ppm\":    \"CU\"\n",
    "    }\n",
    "    out = df.rename(columns=rename_map).copy()\n",
    "    for c in [\"LON\", \"LAT\", \"FROM\", \"TO\", \"CU\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"LON\", \"LAT\", \"FROM\", \"TO\", \"CU\"])\n",
    "    out = out.loc[out[\"FROM\"] < out[\"TO\"]]\n",
    "    return out\n",
    "\n",
    "def standardize_surface(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure surface dataframe has consistent columns:\n",
    "    LON, LAT, CU (no depth).\n",
    "    Accepts DLAT/DLONG or LATITUDE/LONGITUDE.\n",
    "    \"\"\"\n",
    "    rename_map = {\n",
    "        \"DLAT\":      \"LAT\",\n",
    "        \"DLONG\":     \"LON\",\n",
    "        \"LATITUDE\":  \"LAT\",\n",
    "        \"LONGITUDE\": \"LON\",\n",
    "        \"Cu_ppm\":    \"CU\",\n",
    "    }\n",
    "    out = df.rename(columns=rename_map).copy()\n",
    "    for c in [\"LON\", \"LAT\", \"CU\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"LON\", \"LAT\", \"CU\"])\n",
    "    return out\n",
    "\n",
    "# --- XY grid helpers used by both drillhole & surface ---\n",
    "\n",
    "def snap_xy_to_grid(df: pd.DataFrame, step: float = GRID_STEP_DEG) -> pd.DataFrame:\n",
    "    \"\"\"Add integer XY grid indices: _gx, _gy.\"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"_gx\"] = np.floor(out[\"LON\"] / step).astype(np.int64)\n",
    "    out[\"_gy\"] = np.floor(out[\"LAT\"] / step).astype(np.int64)\n",
    "    return out\n",
    "\n",
    "def grid_cell_centers(gx: np.ndarray, gy: np.ndarray, step: float = GRID_STEP_DEG) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Convert integer grid indices (_gx, _gy) to cell-center lon/lat.\"\"\"\n",
    "    lon = (gx + 0.5) * step\n",
    "    lat = (gy + 0.5) * step\n",
    "    return lon, lat\n",
    "\n",
    "def count_xy_cells(df: pd.DataFrame) -> int:\n",
    "    \"\"\"Number of unique XY grid cells in a frame that already has _gx/_gy.\"\"\"\n",
    "    if (\"_gx\" not in df.columns) or (\"_gy\" not in df.columns):\n",
    "        return 0\n",
    "    return int(df.drop_duplicates([\"_gx\", \"_gy\"]).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e771a1",
   "metadata": {},
   "source": [
    " Drillhole split（overlap / orig-only / dl-only）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96ffe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drillhole splitting by XY cell and overlapping depth intervals ---\n",
    "\n",
    "def split_drillhole_overlap(\n",
    "    df_orig: pd.DataFrame,\n",
    "    df_dl: pd.DataFrame,\n",
    "    grid_step: float = GRID_STEP_DEG,\n",
    "    diff_mode: str = DIFF_MODE,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Return (overlap_df, orig_only_df, dl_only_df) for drillhole:\n",
    "    - Overlap requires same XY grid cell AND overlapping depth intervals.\n",
    "    - orig-only: ORIG intervals with no DL overlap in the same XY cell.\n",
    "    - dl-only:   DL intervals with no ORIG overlap in the same XY cell.\n",
    "    \"\"\"\n",
    "    A = snap_xy_to_grid(df_orig, step=grid_step).reset_index(drop=False).rename(columns={\"index\":\"_idxA\"})\n",
    "    B = snap_xy_to_grid(df_dl,   step=grid_step).reset_index(drop=False).rename(columns={\"index\":\"_idxB\"})\n",
    "\n",
    "    overlaps: List[pd.DataFrame] = []\n",
    "    orig_only_rows: List[pd.DataFrame] = []\n",
    "    dl_only_rows: List[pd.DataFrame] = []\n",
    "\n",
    "    for (gx, gy), gA in A.groupby([\"_gx\", \"_gy\"]):\n",
    "        gB = B[(B[\"_gx\"] == gx) & (B[\"_gy\"] == gy)]\n",
    "        if gB.empty:\n",
    "            orig_only_rows.append(gA)\n",
    "            continue\n",
    "\n",
    "        a = gA.rename(columns={\"FROM\":\"fromA\", \"TO\":\"toA\", \"CU\":\"Cu_orig\", \"LON\":\"lonA\", \"LAT\":\"latA\"})\n",
    "        b = gB.rename(columns={\"FROM\":\"fromB\", \"TO\":\"toB\", \"CU\":\"Cu_dl\",   \"LON\":\"lonB\", \"LAT\":\"latB\"})\n",
    "        a[\"__k\"] = 1; b[\"__k\"] = 1\n",
    "        M = a.merge(b, on=\"__k\", how=\"inner\").drop(columns=\"__k\")\n",
    "\n",
    "        if M.empty:\n",
    "            orig_only_rows.append(gA)\n",
    "            continue\n",
    "\n",
    "        M = M.loc[(M[\"fromA\"] < M[\"toB\"]) & (M[\"fromB\"] < M[\"toA\"])].copy()\n",
    "        if M.empty:\n",
    "            orig_only_rows.append(gA)\n",
    "            continue\n",
    "\n",
    "        M[\"from\"] = M[[\"fromA\", \"fromB\"]].max(axis=1)\n",
    "        M[\"to\"]   = M[[\"toA\",   \"toB\"]].min(axis=1)\n",
    "        M = M.loc[M[\"from\"] < M[\"to\"]].copy()\n",
    "        if M.empty:\n",
    "            orig_only_rows.append(gA)\n",
    "            continue\n",
    "\n",
    "        if diff_mode == \"dl_minus_orig\":\n",
    "            M[\"diff\"] = M[\"Cu_dl\"] - M[\"Cu_orig\"]\n",
    "        else:\n",
    "            M[\"diff\"] = M[\"Cu_orig\"] - M[\"Cu_dl\"]\n",
    "\n",
    "        eps = 1e-9\n",
    "        denom = M[\"Cu_dl\"].where(M[\"Cu_dl\"].abs() >= eps, np.nan)\n",
    "        M[\"diff_pct\"] = 100.0 * M[\"diff\"] / denom\n",
    "\n",
    "        M[\"_gx\"] = gx; M[\"_gy\"] = gy\n",
    "        overlaps.append(M[[\n",
    "            \"from\",\"to\",\"Cu_orig\",\"Cu_dl\",\"diff\",\"diff_pct\",\n",
    "            \"lonA\",\"latA\",\"lonB\",\"latB\",\"_gx\",\"_gy\",\"_idxA\",\"_idxB\"\n",
    "        ]])\n",
    "\n",
    "        usedA = set(M[\"_idxA\"].unique())\n",
    "        usedB = set(M[\"_idxB\"].unique())\n",
    "        if len(usedA) < len(gA):\n",
    "            orig_only_rows.append(gA.loc[~gA[\"_idxA\"].isin(usedA)])\n",
    "        if len(usedB) < len(gB):\n",
    "            dl_only_rows.append(gB.loc[~gB[\"_idxB\"].isin(usedB)])\n",
    "\n",
    "    overlap_df = pd.concat(overlaps, ignore_index=True) if overlaps else pd.DataFrame(\n",
    "        columns=[\"from\",\"to\",\"Cu_orig\",\"Cu_dl\",\"diff\",\"diff_pct\",\"lonA\",\"latA\",\"lonB\",\"latB\",\"_gx\",\"_gy\",\"_idxA\",\"_idxB\"]\n",
    "    )\n",
    "    orig_only_df = pd.concat(orig_only_rows, ignore_index=True) if orig_only_rows else pd.DataFrame(columns=A.columns)\n",
    "    dl_only_df   = pd.concat(dl_only_rows,   ignore_index=True) if dl_only_rows   else pd.DataFrame(columns=B.columns)\n",
    "\n",
    "    return overlap_df, orig_only_df, dl_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1c49d",
   "metadata": {},
   "source": [
    "Intervals → 3D points/voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343500ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert drillhole intervals to representative 3D points (for Streamlit) ---\n",
    "\n",
    "def dh_intervals_to_points(\n",
    "    overlap_df: pd.DataFrame,\n",
    "    orig_only_df: pd.DataFrame,\n",
    "    dl_only_df: pd.DataFrame,\n",
    "    grid_step: float = GRID_STEP_DEG,\n",
    "    z_step: float = Z_STEP_M,\n",
    "    agg: str = \"mean\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Build 3D points for three sources (overlap / orig-only / dl-only) and an 'all' union.\n",
    "    Each point: LONGITUDE, LATITUDE, DEPTH, CU_ORIG, CU_DL, DIFF, DIFF_PCT, SOURCE\n",
    "    Returns (pts_overlap, pts_origonly, pts_dlonly, pts_all, counts_dict)\n",
    "    \"\"\"\n",
    "    def _bin_and_agg(df_pts: pd.DataFrame) -> pd.DataFrame:\n",
    "        if df_pts.empty:\n",
    "            return df_pts\n",
    "        df = df_pts.copy()\n",
    "        df[\"_gx\"] = np.floor(df[\"LONGITUDE\"]/grid_step).astype(np.int64)\n",
    "        df[\"_gy\"] = np.floor(df[\"LATITUDE\"] /grid_step).astype(np.int64)\n",
    "        df[\"_gz\"] = np.floor(df[\"DEPTH\"]   /z_step   ).astype(np.int64)\n",
    "        grouped = (\n",
    "            df.groupby([\"_gx\",\"_gy\",\"_gz\",\"SOURCE\"], as_index=False)\n",
    "              .agg({\n",
    "                  \"LONGITUDE\":agg, \"LATITUDE\":agg, \"DEPTH\":agg,\n",
    "                  \"CU_ORIG\":agg, \"CU_DL\":agg, \"DIFF\":agg, \"DIFF_PCT\":agg\n",
    "              })\n",
    "        )\n",
    "        return grouped[[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\",\"SOURCE\",\"_gx\",\"_gy\",\"_gz\"]]\n",
    "\n",
    "    pts_overlap = pd.DataFrame(columns=[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\",\"SOURCE\"])\n",
    "    if not overlap_df.empty:\n",
    "        O = overlap_df.copy()\n",
    "        O[\"DEPTH\"]     = (O[\"from\"] + O[\"to\"]) / 2.0\n",
    "        O[\"LONGITUDE\"] = (O[\"lonA\"] + O[\"lonB\"]) / 2.0\n",
    "        O[\"LATITUDE\"]  = (O[\"latA\"] + O[\"latB\"]) / 2.0\n",
    "        O = O.rename(columns={\"Cu_orig\":\"CU_ORIG\",\"Cu_dl\":\"CU_DL\"})\n",
    "        O[\"SOURCE\"] = \"overlap\"\n",
    "        pts_overlap = O[[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"diff\",\"diff_pct\",\"SOURCE\"]].rename(\n",
    "            columns={\"diff\":\"DIFF\",\"diff_pct\":\"DIFF_PCT\"}\n",
    "        )\n",
    "\n",
    "    pts_origonly = pd.DataFrame(columns=pts_overlap.columns)\n",
    "    if not orig_only_df.empty:\n",
    "        A = orig_only_df.copy()\n",
    "        A[\"DEPTH\"]     = (A[\"FROM\"] + A[\"TO\"]) / 2.0\n",
    "        A[\"LONGITUDE\"] = A[\"LON\"]; A[\"LATITUDE\"] = A[\"LAT\"]\n",
    "        A[\"CU_ORIG\"]   = A[\"CU\"];  A[\"CU_DL\"]    = np.nan\n",
    "        A[\"DIFF\"]      = np.nan;   A[\"DIFF_PCT\"] = np.nan\n",
    "        A[\"SOURCE\"]    = \"orig_only\"\n",
    "        pts_origonly = A[[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\",\"SOURCE\"]]\n",
    "\n",
    "    pts_dlonly = pd.DataFrame(columns=pts_overlap.columns)\n",
    "    if not dl_only_df.empty:\n",
    "        B = dl_only_df.copy()\n",
    "        B[\"DEPTH\"]     = (B[\"FROM\"] + B[\"TO\"]) / 2.0\n",
    "        B[\"LONGITUDE\"] = B[\"LON\"]; B[\"LATITUDE\"] = B[\"LAT\"]\n",
    "        B[\"CU_ORIG\"]   = np.nan;   B[\"CU_DL\"]    = B[\"CU\"]\n",
    "        B[\"DIFF\"]      = np.nan;   B[\"DIFF_PCT\"] = np.nan\n",
    "        B[\"SOURCE\"]    = \"dl_only\"\n",
    "        pts_dlonly = B[[\"LONGITUDE\",\"LATITUDE\",\"DEPTH\",\"CU_ORIG\",\"CU_DL\",\"DIFF\",\"DIFF_PCT\",\"SOURCE\"]]\n",
    "\n",
    "    vox_overlap  = _bin_and_agg(pts_overlap)\n",
    "    vox_origonly = _bin_and_agg(pts_origonly)\n",
    "    vox_dlonly   = _bin_and_agg(pts_dlonly)\n",
    "    vox_all      = pd.concat([vox_overlap, vox_origonly, vox_dlonly], ignore_index=True)\n",
    "\n",
    "    counts = {\n",
    "        # raw counts (approximate back from indices present in splits)\n",
    "        \"raw_orig_rows\": int(orig_only_df.shape[0] + overlap_df[\"_idxA\"].nunique() if not overlap_df.empty else orig_only_df.shape[0]),\n",
    "        \"raw_dl_rows\":   int(dl_only_df.shape[0]   + overlap_df[\"_idxB\"].nunique() if not overlap_df.empty else dl_only_df.shape[0]),\n",
    "        \"vox_overlap\":   int(vox_overlap.drop_duplicates([\"_gx\",\"_gy\",\"_gz\"]).shape[0]),\n",
    "        \"vox_orig_only\": int(vox_origonly.drop_duplicates([\"_gx\",\"_gy\",\"_gz\"]).shape[0]),\n",
    "        \"vox_dl_only\":   int(vox_dlonly.drop_duplicates([\"_gx\",\"_gy\",\"_gz\"]).shape[0]),\n",
    "        \"vox_all\":       int(vox_all.drop_duplicates([\"_gx\",\"_gy\",\"_gz\"]).shape[0]),\n",
    "    }\n",
    "    return vox_overlap, vox_origonly, vox_dlonly, vox_all, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839ca91",
   "metadata": {},
   "source": [
    "Run drillhole pipeline end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575b874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drillhole standardized shapes: (2464631, 9) (920013, 8)\n",
      "[Drillhole] raw rows: overlap pairs=260,797, orig-only=2,317,904, dl-only=109,124\n",
      "[Drillhole] voxel counts: overlap=90,439, orig-only=1,787,661, dl-only=50,084, all=1,926,606\n",
      "[SAVE] Drillhole CSVs written to ../reports/task2/difference\n"
     ]
    }
   ],
   "source": [
    "# --- Run drillhole pipeline end-to-end ---\n",
    "\n",
    "# 1) Standardize\n",
    "dh_orig = standardize_drillhole(df_dh_orig_clean)\n",
    "dh_dl   = standardize_drillhole(df_dh_dl_clean)\n",
    "print(\"Drillhole standardized shapes:\", dh_orig.shape, dh_dl.shape)\n",
    "\n",
    "# 2) Split by overlap\n",
    "dh_overlap, dh_orig_only, dh_dl_only = split_drillhole_overlap(dh_orig, dh_dl)\n",
    "print(\"[Drillhole] raw rows:\",\n",
    "      f\"overlap pairs={len(dh_overlap):,}, orig-only={len(dh_orig_only):,}, dl-only={len(dh_dl_only):,}\")\n",
    "\n",
    "# 3) Convert intervals -> 3D voxel points\n",
    "pts_overlap, pts_origonly, pts_dlonly, pts_all, dh_counts = dh_intervals_to_points(\n",
    "    dh_overlap, dh_orig_only, dh_dl_only\n",
    ")\n",
    "print(\"[Drillhole] voxel counts:\",\n",
    "      f\"overlap={dh_counts['vox_overlap']:,}, orig-only={dh_counts['vox_orig_only']:,},\",\n",
    "      f\"dl-only={dh_counts['vox_dl_only']:,}, all={dh_counts['vox_all']:,}\")\n",
    "\n",
    "# 4) Export CSVs for Streamlit (3D viewer)\n",
    "pts_overlap.to_csv(OUT_DIR / \"drillhole_points_overlap.csv\", index=False)\n",
    "pts_origonly.to_csv(OUT_DIR / \"drillhole_points_origonly.csv\", index=False)\n",
    "pts_dlonly  .to_csv(OUT_DIR / \"drillhole_points_dlonly.csv\", index=False)\n",
    "pts_all     .to_csv(OUT_DIR / \"drillhole_points_all.csv\", index=False)\n",
    "\n",
    "# Also keep interval-level overlap table (useful for audit)\n",
    "dh_overlap.to_csv(OUT_DIR / \"drillhole_overlaps.csv\", index=False)\n",
    "\n",
    "print(\"[SAVE] Drillhole CSVs written to\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddee6f4",
   "metadata": {},
   "source": [
    "Summary for drillhole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e84594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100.0\u001b[39m\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m/\u001b[39md\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1) Raw rows\u001b[39;00m\n\u001b[1;32m      5\u001b[0m rows_raw \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 6\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORIG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mraw_orig\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDL\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_dl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 2) XY cells\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rows_xy \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXY grid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORIG\u001b[39m\u001b[38;5;124m\"\u001b[39m, xy_orig, pretty_pct(xy_orig, raw_orig)],\n\u001b[1;32m     13\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXY grid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDL\u001b[39m\u001b[38;5;124m\"\u001b[39m, xy_dl, pretty_pct(xy_dl, raw_dl)],\n\u001b[1;32m     14\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_orig' is not defined"
     ]
    }
   ],
   "source": [
    "def pretty_pct(n, d):\n",
    "    return \"-\" if d == 0 else f\"{100.0*n/d:.2f}%\"\n",
    "\n",
    "# 1) Raw rows\n",
    "rows_raw = [\n",
    "    [\"Raw rows\", \"ORIG\", raw_orig, \"-\"],\n",
    "    [\"Raw rows\", \"DL\", raw_dl, \"-\"],\n",
    "]\n",
    "\n",
    "# 2) XY cells\n",
    "rows_xy = [\n",
    "    [\"XY grid\", \"ORIG\", xy_orig, pretty_pct(xy_orig, raw_orig)],\n",
    "    [\"XY grid\", \"DL\", xy_dl, pretty_pct(xy_dl, raw_dl)],\n",
    "]\n",
    "\n",
    "# 3) Interval split\n",
    "total_interval_rows = len(dh_overlap) + len(dh_orig_only) + len(dh_dl_only)\n",
    "rows_interval = [\n",
    "    [\"Interval split\", \"Overlap\",   len(dh_overlap),   pretty_pct(len(dh_overlap), total_interval_rows)],\n",
    "    [\"Interval split\", \"Orig-only\", len(dh_orig_only), pretty_pct(len(dh_orig_only), total_interval_rows)],\n",
    "    [\"Interval split\", \"DL-only\",   len(dh_dl_only),   pretty_pct(len(dh_dl_only), total_interval_rows)],\n",
    "    [\"Interval split\", \"TOTAL\",     total_interval_rows, \"100.0%\"],\n",
    "]\n",
    "\n",
    "# 4) Voxel split\n",
    "vox_overlap  = dh_counts[\"vox_overlap\"]\n",
    "vox_origonly = dh_counts[\"vox_orig_only\"]\n",
    "vox_dlonly   = dh_counts[\"vox_dl_only\"]\n",
    "vox_all      = dh_counts[\"vox_all\"]\n",
    "\n",
    "rows_voxel = [\n",
    "    [\"Voxel split\", \"Overlap\",   vox_overlap,   pretty_pct(vox_overlap, vox_all)],\n",
    "    [\"Voxel split\", \"Orig-only\", vox_origonly, pretty_pct(vox_origonly, vox_all)],\n",
    "    [\"Voxel split\", \"DL-only\",   vox_dlonly,   pretty_pct(vox_dlonly, vox_all)],\n",
    "    [\"Voxel split\", \"TOTAL\",     vox_all, \"100.0%\"],\n",
    "]\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "tbl_all = pd.DataFrame(rows_raw + rows_xy + rows_interval + rows_voxel,\n",
    "                       columns=[\"Stage\",\"Dataset\",\"Count\",\"% of Stage\"])\n",
    "\n",
    "display(tbl_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5954e",
   "metadata": {},
   "source": [
    "Interpretation of Table\n",
    "- Raw rows (ORIG, DL): The original cleaned drillhole records and the deep learning (DL) imputed dataset. \n",
    "- XY grid: After snapping coordinates to a regular 10m × 10m grid. The count shows how many unique spatial cells are occupied by each dataset, relative to their raw rows.\n",
    "- Interval split: Partition of intervals within each grid cell.\n",
    "\t- Overlap: ORIG and DL both have values in the same depth range (used to compare DL predictions vs. real measurements).\n",
    "\t- Orig-only: ORIG has values but DL did not impute (baseline data).\n",
    "\t- DL-only: DL predicted values where ORIG had missing data (new information).\n",
    "- Voxel split: Final 3D aggregation into 10m × 10m × 1m voxels.\n",
    "\t- Overlap voxels show where ORIG and DL can be directly compared.\n",
    "\t- Orig-only voxels dominate, representing the baseline dataset.\n",
    "\t- DL-only voxels are smaller in number (~2.6%) but represent the incremental insights brought by DL. These are the areas with the highest potential exploration value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede4187",
   "metadata": {},
   "source": [
    "Surface: XY Overlap / Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Surface comparison at XY grid cell level (no depth) ---\n",
    "\n",
    "def surface_xy_grids(df: pd.DataFrame, grid_step: float = GRID_STEP_DEG, agg: str = \"mean\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate surface points into XY grid cells with CU summary and count.\n",
    "    Returns columns: _gx, _gy, LONc, LATc, CU, COUNT\n",
    "    \"\"\"\n",
    "    D = snap_xy_to_grid(df, step=grid_step)\n",
    "    agg_df = (\n",
    "        D.groupby([\"_gx\",\"_gy\"], as_index=False)\n",
    "         .agg(CU=(\"CU\", agg), COUNT=(\"CU\", \"size\"))\n",
    "    )\n",
    "    LONc, LATc = grid_cell_centers(agg_df[\"_gx\"].to_numpy(), agg_df[\"_gy\"].to_numpy(), step=grid_step)\n",
    "    agg_df[\"LONc\"] = LONc; agg_df[\"LATc\"] = LATc\n",
    "    return agg_df[[\"_gx\",\"_gy\",\"LONc\",\"LATc\",\"CU\",\"COUNT\"]]\n",
    "\n",
    "def split_surface_overlap(\n",
    "    sf_orig_grid: pd.DataFrame,\n",
    "    sf_dl_grid: pd.DataFrame\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Return (overlap_grid, orig_only_grid, dl_only_grid) at grid-cell level.\n",
    "    For overlap cells, include CU_ORIG, CU_DL, DIFF, DIFF_PCT.\n",
    "    \"\"\"\n",
    "    A = sf_orig_grid.rename(columns={\"CU\":\"CU_ORIG\",\"COUNT\":\"COUNT_ORIG\"})\n",
    "    B = sf_dl_grid  .rename(columns={\"CU\":\"CU_DL\",  \"COUNT\":\"COUNT_DL\"})\n",
    "\n",
    "    M = A.merge(B, on=[\"_gx\",\"_gy\"], how=\"outer\", indicator=True)\n",
    "\n",
    "    overlap = M.loc[M[\"_merge\"]==\"both\"].copy()\n",
    "    overlap[\"DIFF\"] = overlap[\"CU_DL\"] - overlap[\"CU_ORIG\"]\n",
    "    eps = 1e-9\n",
    "    denom = overlap[\"CU_DL\"].where(overlap[\"CU_DL\"].abs()>=eps, np.nan)\n",
    "    overlap[\"DIFF_PCT\"] = 100.0 * overlap[\"DIFF\"] / denom\n",
    "\n",
    "    orig_only = M.loc[M[\"_merge\"]==\"left_only\"].copy()\n",
    "    dl_only   = M.loc[M[\"_merge\"]==\"right_only\"].copy()\n",
    "\n",
    "    return overlap, orig_only, dl_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa0d19",
   "metadata": {},
   "source": [
    "Run: Drillhole end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e19f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drillhole standardized shapes: (2464631, 9) (920013, 8)\n",
      "[Drillhole] raw rows: overlap pairs=260,797, orig-only=2,317,904, dl-only=109,124\n",
      "[Drillhole] voxel counts: overlap=90,439, orig-only=1,787,661, dl-only=50,084, all=1,926,606\n",
      "[SAVE] Drillhole CSVs written to ../reports/task2\n"
     ]
    }
   ],
   "source": [
    "# --- Run drillhole pipeline end-to-end ---\n",
    "\n",
    "# 1) Standardize\n",
    "dh_orig = standardize_drillhole(df_dh_orig_clean)\n",
    "dh_dl   = standardize_drillhole(df_dh_dl_clean)\n",
    "\n",
    "print(\"Drillhole standardized shapes:\", dh_orig.shape, dh_dl.shape)\n",
    "\n",
    "# 2) Split by overlap\n",
    "dh_overlap, dh_orig_only, dh_dl_only = split_drillhole_overlap(dh_orig, dh_dl)\n",
    "\n",
    "print(\"[Drillhole] raw rows:\",\n",
    "      f\"overlap pairs={len(dh_overlap):,}, orig-only={len(dh_orig_only):,}, dl-only={len(dh_dl_only):,}\")\n",
    "\n",
    "# 3) Convert intervals -> 3D voxel points\n",
    "pts_overlap, pts_origonly, pts_dlonly, pts_all, dh_counts = dh_intervals_to_points(\n",
    "    dh_overlap, dh_orig_only, dh_dl_only\n",
    ")\n",
    "\n",
    "print(\"[Drillhole] voxel counts:\",\n",
    "      f\"overlap={dh_counts['vox_overlap']:,}, orig-only={dh_counts['vox_orig_only']:,},\",\n",
    "      f\"dl-only={dh_counts['vox_dl_only']:,}, all={dh_counts['vox_all']:,}\")\n",
    "\n",
    "# 4) Export CSVs for Streamlit (3D viewer)\n",
    "pts_overlap.to_csv(OUT_DIR/\"drillhole_points_overlap.csv\", index=False)\n",
    "pts_origonly.to_csv(OUT_DIR/\"drillhole_points_origonly.csv\", index=False)\n",
    "pts_dlonly  .to_csv(OUT_DIR/\"drillhole_points_dlonly.csv\", index=False)\n",
    "pts_all     .to_csv(OUT_DIR/\"drillhole_points_all.csv\", index=False)\n",
    "\n",
    "# Also keep interval-level overlap table (useful for audit)\n",
    "dh_overlap.to_csv(OUT_DIR/\"drillhole_overlaps.csv\", index=False)\n",
    "\n",
    "print(\"[SAVE] Drillhole CSVs written to\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f40d4c",
   "metadata": {},
   "source": [
    "Run: Surface end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run surface pipeline end-to-end (2D grids) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40c8f",
   "metadata": {},
   "source": [
    "Quick Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761b9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Raw rows (orig)</th>\n",
       "      <th>Raw rows (dl)</th>\n",
       "      <th>Grid voxels (all)</th>\n",
       "      <th>Voxels overlap</th>\n",
       "      <th>Voxels orig-only</th>\n",
       "      <th>Voxels dl-only</th>\n",
       "      <th>Grid cells (orig)</th>\n",
       "      <th>Grid cells (dl)</th>\n",
       "      <th>Cells overlap</th>\n",
       "      <th>Cells orig-only</th>\n",
       "      <th>Cells dl-only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drillhole</td>\n",
       "      <td>2464631</td>\n",
       "      <td>920013</td>\n",
       "      <td>1926606.0</td>\n",
       "      <td>90439.0</td>\n",
       "      <td>1787661.0</td>\n",
       "      <td>50084.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surface</td>\n",
       "      <td>981318</td>\n",
       "      <td>544886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>683953.0</td>\n",
       "      <td>403109.0</td>\n",
       "      <td>48319.0</td>\n",
       "      <td>635634.0</td>\n",
       "      <td>354790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Raw rows (orig)  Raw rows (dl)  Grid voxels (all)  \\\n",
       "0  Drillhole          2464631         920013          1926606.0   \n",
       "1    Surface           981318         544886                NaN   \n",
       "\n",
       "   Voxels overlap  Voxels orig-only  Voxels dl-only  Grid cells (orig)  \\\n",
       "0         90439.0         1787661.0         50084.0                NaN   \n",
       "1             NaN               NaN             NaN           683953.0   \n",
       "\n",
       "   Grid cells (dl)  Cells overlap  Cells orig-only  Cells dl-only  \n",
       "0              NaN            NaN              NaN            NaN  \n",
       "1         403109.0        48319.0         635634.0       354790.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Summary table for slides: raw vs grid vs split counts ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
